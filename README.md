# ðŸ¾ Scrapy4Paws ðŸ¾

A web scraping application that collects information about animals available for adoption from shelters. Built with FastAPI, PostgreSQL, and Streamlit. The project is designed with extensibility in mind, allowing for easy addition of more shelters in the future.

## ðŸŒŸ Features

- Automated scraping of cat adoption information 
- RESTful API for accessing the collected data
- Interactive web interface built with Streamlit
- PostgreSQL database for data storage
- Docker containerization for easy deployment
- Alembic migrations for database management
- Modular scraper architecture for easy integration of new shelters

## ðŸ› ï¸ Tech Stack

- **Backend**: FastAPI, SQLAlchemy
- **Frontend**: Streamlit
- **Database**: PostgreSQL
- **Scraping**: BeautifulSoup4
- **Containerization**: Docker, Docker Compose
- **Database Migrations**: Alembic

## ðŸš€ Getting Started

### Prerequisites

- Docker
- Docker Compose

### Installation

1. Clone the repository:
```bash
git clone https://github.com/MarynaDRST/Scrapy4Paws.git
cd scrapy4paws
```

2. Create a `.env` file based on `.env.example`:
```bash
cp .env.example .env
```

3. Update the `.env` file with your database credentials and other settings.

4. Build and start the containers:
```bash
docker-compose up -d
```

The application will be available at:
- Frontend: http://localhost:8501
- API: http://localhost:8000
- API Documentation: http://localhost:8000/docs

## ðŸ“ Project Structure

```
scrapy4paws/
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ config/         # Configuration files
â”‚   â”œâ”€â”€ models/         # Database models
â”‚   â”œâ”€â”€ schemas/        # Pydantic schemas
â”‚   â”œâ”€â”€ scripts/        # Utility scripts
â”‚   â””â”€â”€ scrapers/       # Web scrapers
â”‚   â””â”€â”€ alembic/        # Database migrations
â”œâ”€â”€ frontend/           # Streamlit frontend
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

## ðŸ”„ Database Migrations

To apply database migrations:
```bash
docker-compose exec api alembic upgrade head
```

To create a new migration:
```bash
docker-compose exec api alembic revision --autogenerate -m "description"
```

## ðŸ± Available Endpoints

- `GET /api/animals` - Get all animals
- `GET /api/animals/{id}` - Get animal by ID
- `PUT /api/animals/{id}` - Update animal information

## ðŸ” Scraping

The application automatically scrapes data from Nuevavida shelter website. The scraper runs when the application starts and collects:
- Animal names
- Ages
- Genders
- Descriptions
- Images
- Shelter information

> âš ï¸ **Important Note**: The website's domain was changed on March 23rd, 2024, requiring project adaptation. If scraping fails, please check:
> - Website URL accessibility
> - Website structure and selectors (they may have changed)
> - Website's robots.txt and scraping policies




